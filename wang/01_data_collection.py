import pandas as pd
import yfinance as yf
from gnews import GNews
from tqdm import tqdm
import time
import datetime
from newspaper import Article

# ================= é…ç½®åŒºåŸŸ =================
# æˆ‘ä»¬åªå…³æ³¨è¿™ä¸€æ¡â€œAI é»„é‡‘ä¾›åº”é“¾â€ï¼Œé€»è¾‘æœ€å¼º
TARGET_TICKERS = ["NVDA", "TSM", "AMD", "MSFT", "AAPL", "GOOGL", "META"]

# æ—¶é—´èŒƒå›´ (å»ºè®®çˆ¬è¿‡å» 1-2 å¹´çš„ï¼Œæ•°æ®é‡æ­£å¥½é€‚åˆå¾®è°ƒ)
START_DATE = (datetime.datetime.now() - datetime.timedelta(days=800)).strftime("%Y-%m-%d") # è¿‡å»ä¸€å¹´
END_DATE = datetime.datetime.now().strftime("%Y-%m-%d")

OUTPUT_FILE = "my_custom_fin_dataset_2025.csv"

# ================= 1. æ–°é—»çˆ¬è™« (Google News) =================
def fetch_google_news(tickers):
    print(f"ğŸ•·ï¸ [1/3] å¯åŠ¨ Google News çˆ¬è™« ({START_DATE} - {END_DATE})...")
    
    google_news = GNews(language='en', country='US', period='2y', max_results=100) # è¿™é‡Œçš„ period å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
    all_news = []
    
    for ticker in tqdm(tickers):
        # æœç´¢å…³é”®è¯ï¼šå…¬å¸è‚¡ç¥¨ä»£ç  + "stock" æˆ–è€… "revenue" ç­‰è¯ï¼Œæé«˜ç›¸å…³æ€§
        keyword = f"{ticker} stock news"
        json_resp = google_news.get_news(keyword)
        
        for article in json_resp:
            # ç®€å•æ¸…æ´—
            title = article.get('title', '')
            pub_date = article.get('published date', '')
            url = article.get('url', '')
            
            # è¿‡æ»¤æ‰å¤ªçŸ­çš„æ ‡é¢˜
            if len(title) < 10: continue
            
            # æ ¼å¼åŒ–æ—¥æœŸ (GNews è¿”å›çš„æ ¼å¼å¾ˆä¹±ï¼Œéœ€è¦ç»Ÿä¸€)
            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå°è¯•è§£æï¼Œè§£æä¸äº†å°±è·³è¿‡
            try:
                # GNews æ ¼å¼é€šå¸¸æ˜¯: "Fri, 27 Dec 2024 07:00:00 GMT"
                dt = pd.to_datetime(pub_date).strftime("%Y-%m-%d")
            except:
                dt = datetime.datetime.now().strftime("%Y-%m-%d") # å…œåº•
                
            all_news.append({
                'Date': dt,
                'Ticker': ticker,
                'Headline': title,
                'Source': article.get('publisher', {}).get('title', 'Unknown'),
                'URL': url
            })
            
        # ç¤¼è²Œå»¶æ—¶ï¼Œé˜²æ­¢ Google å° IP
        time.sleep(2)
        
    df_news = pd.DataFrame(all_news)
    # å»é‡ (ä¸åŒå…³é”®è¯å¯èƒ½çˆ¬åˆ°åŒä¸€æ¡æ–°é—»)
    df_news = df_news.drop_duplicates(subset=['Headline'])
    print(f"   -> çˆ¬å–å®Œæˆï¼Œå…± {len(df_news)} æ¡åŸå§‹æ–°é—»")
    return df_news

# ================= 2. è‚¡ä»·è·å–ä¸æ ‡ç­¾ç”Ÿæˆ =================
def align_prices_and_label(news_df):
    print("ğŸ“ˆ [2/3] ä¸‹è½½è‚¡ä»·å¹¶ç”Ÿæˆã€æ¶¨è·Œæ ‡ç­¾ã€‘...")
    
    final_data = []
    unique_tickers = news_df['Ticker'].unique()
    
    # æ‰¹é‡ä¸‹è½½è‚¡ä»·
    prices = yf.download(list(unique_tickers), start=START_DATE, end=END_DATE)['Close']
    
    # è®¡ç®— T+1 æ”¶ç›Šç‡
    # Shift(-1) å› ä¸ºæˆ‘ä»¬ç”¨ã€ä»Šå¤©çš„æ–°é—»ã€‘é¢„æµ‹ã€æ˜å¤©çš„æ¶¨è·Œã€‘
    returns = prices.pct_change().shift(-1)
    
    for idx, row in tqdm(news_df.iterrows(), total=len(news_df)):
        ticker = row['Ticker']
        date_str = row['Date']
        
        try:
            # æŸ¥æ‰¾å½“å¤©çš„æ”¶ç›Šç‡
            # æ³¨æ„ï¼šå¦‚æœæ–°é—»æ˜¯å‘¨æœ«å‘çš„ï¼Œæˆ‘ä»¬è¦å¯¹åº”åˆ°å‘¨ä¸€çš„æ”¶ç›Šç‡
            # è¿™é‡Œç”¨ asof æ‰¾æœ€è¿‘çš„äº¤æ˜“æ—¥
            dt = pd.to_datetime(date_str)
            if dt not in returns.index:
                # æ‰¾æœ€è¿‘çš„ä¸€ä¸ªæœªæ¥äº¤æ˜“æ—¥
                valid_dates = returns.index[returns.index > dt]
                if len(valid_dates) == 0: continue
                target_date = valid_dates[0]
            else:
                target_date = dt
                
            ret = returns.loc[target_date][ticker]
            
            # æ‰“æ ‡ç­¾ (Labeling)
            # æ¶¨ (UP): > 0.5%
            # è·Œ (DOWN): < -0.5%
            # éœ‡è¡ (NEUTRAL): -0.5% ~ 0.5%
            
            label = "NEUTRAL"
            if ret > 0.005: label = "UP"
            elif ret < -0.005: label = "DOWN"
            
            # åªæœ‰æ˜ç¡®çš„æ¶¨è·Œæ‰é€‚åˆè®­ç»ƒ LLMï¼Œéœ‡è¡æ•°æ®å¯èƒ½ä¼šé€ æˆæ··æ·†
            # ç­–ç•¥ï¼šä¿ç•™éœ‡è¡æ•°æ®ä½†æ ‡è®°ï¼Œæˆ–è€…ç›´æ¥ä¸¢å¼ƒã€‚ä¸ºäº†è®­ç»ƒæ•ˆæœï¼Œå»ºè®®ä¿ç•™æˆ–ä¸¢å¼ƒã€‚
            
            # æ„å»º CoT (æ€ç»´é“¾) è®­ç»ƒæ•°æ®æ‰€éœ€çš„ "Reasoning" (ä¼ªé€ /æ¨æ–­)
            # æ³¨æ„ï¼šåœ¨çœŸå®å¾®è°ƒæ—¶ï¼Œæˆ‘ä»¬ä¼šè®© LLM è‡ªå·±å­¦ reasoningï¼Œ
            # è¿™é‡Œæˆ‘ä»¬å…ˆå‡†å¤‡å¥½ Input (Headline) å’Œ Output (Label)
            
            final_data.append({
                'Date': date_str,
                'Ticker': ticker,
                'Headline': row['Headline'],
                'Source': row['Source'],
                'Next_Day_Return': ret,
                'Label': label
            })
            
        except Exception as e:
            continue
            
    df_final = pd.DataFrame(final_data)
    # è¿‡æ»¤æ‰ Neutral (å¯é€‰ï¼Œå¦‚æœä½ æƒ³åšäºŒåˆ†ç±»)
    # df_final = df_final[df_final['Label'] != "NEUTRAL"]
    
    return df_final

# ================= 3. ä¸»ç¨‹åº =================
if __name__ == "__main__":
    # 1. çˆ¬æ–°é—»
    news_df = fetch_google_news(TARGET_TICKERS)
    
    if not news_df.empty:
        # 2. å¯¹é½è‚¡ä»·
        dataset = align_prices_and_label(news_df)
        
        # 3. ä¿å­˜
        dataset.to_csv(OUTPUT_FILE, index=False)
        print(f"âœ… æ•°æ®é›†æ„å»ºå®Œæˆï¼ä¿å­˜ä¸º: {OUTPUT_FILE}")
        print(f"   æœ‰æ•ˆæ ·æœ¬æ•°: {len(dataset)}")
        print("   ç°åœ¨ä½ å¯ä»¥ç”¨è¿™ä¸ª CSV å»å–‚ç»™ Llama-3 äº†ï¼")
        print("\næ ·æœ¬é¢„è§ˆ:")
        print(dataset[['Date', 'Ticker', 'Headline', 'Label']].head())
    else:
        print("âŒ æ²¡çˆ¬åˆ°æ–°é—»ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ (å¯èƒ½éœ€è¦æ¢¯å­è¿æ¥ Google)ã€‚")